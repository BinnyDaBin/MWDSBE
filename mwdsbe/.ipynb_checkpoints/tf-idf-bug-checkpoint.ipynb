{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import sparse_dot_topn.sparse_dot_topn as ct\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import mwdsbe\n",
    "import mwdsbe.datasets.licenses as licenses\n",
    "import schuylkill as skool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry = mwdsbe.load_registry() # geopandas df\n",
    "license = licenses.CommercialActivityLicenses().get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data\n",
    "ignore_words = ['inc', 'group', 'llc', 'corp', 'pc', 'incorporated', 'ltd', 'co', 'associates', 'services', 'company', 'enterprises', 'enterprise', 'service', 'corporation']\n",
    "cleaned_registry = skool.clean_strings(registry, ['company_name', 'dba_name'], True, ignore_words)\n",
    "cleaned_license = skool.clean_strings(license, ['company_name'], True, ignore_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_merge(\n",
    "    left: pd.DataFrame,\n",
    "    right: pd.DataFrame,\n",
    "    on: str = None,\n",
    "    left_on: str = None,\n",
    "    right_on: str = None,\n",
    "    score_cutoff: int = 90,\n",
    "    max_matches=1,\n",
    "    suffixes=(\"_x\", \"_y\"),\n",
    "):\n",
    "    if on is not None:\n",
    "        left_on = right_on = on\n",
    "\n",
    "    # Verify input parameters\n",
    "    if left_on is None or right_on is None:\n",
    "        raise ValueError(\"Please specify `on` or `left_on/right_on`\")\n",
    "    if left_on not in left.columns:\n",
    "        raise ValueError(f\"'{left_on}' is not a column in `left`\")\n",
    "    if right_on not in right.columns:\n",
    "        raise ValueError(f\"'{right_on}' is not a column in `right`\")\n",
    "\n",
    "    # get the left and right strings\n",
    "    left_data = left[left_on].dropna().astype(str)\n",
    "    right_data = right[right_on].dropna().astype(str).rename_axis(\"right_index\")\n",
    "    \n",
    "    print(left_data)\n",
    "    print(right_data)\n",
    "\n",
    "    # Merge together into single Series\n",
    "    all_data = pd.concat([left_data, right_data], axis=0)\n",
    "    all_data_unique = pd.concat(\n",
    "        [left_data.drop_duplicates(), right_data.drop_duplicates()], axis=0\n",
    "    )\n",
    "\n",
    "    # save the index and then reset it\n",
    "    unique_index = all_data_unique.index\n",
    "    all_data_unique = all_data_unique.reset_index(drop=True)\n",
    "\n",
    "    # Do the TF-IDF vectorization\n",
    "    vectorizer = TfidfVectorizer(min_df=1, analyzer=_ngrams)\n",
    "    tf_idf_matrix = vectorizer.fit_transform(all_data_unique.values)\n",
    "\n",
    "    # Get the matches as a sparse matrix\n",
    "    matches = _fast_cossim_top(\n",
    "        tf_idf_matrix,\n",
    "        tf_idf_matrix.transpose(),\n",
    "        ntop=max_matches + 1,\n",
    "        lower_bound=score_cutoff / 100,\n",
    "    )\n",
    "\n",
    "    # Format the matches into a DataFrame\n",
    "    left_size = len(left_data)\n",
    "    matches_df = _format_matches(matches, all_data_unique, unique_index, left_size)\n",
    "\n",
    "    # Merge in the right\n",
    "    matches_df = (\n",
    "        pd.merge(\n",
    "            left,\n",
    "            pd.merge(\n",
    "                matches_df,\n",
    "                right.rename_axis(\"right_index\").reset_index(),\n",
    "                on=\"right_index\",\n",
    "            ).set_index(\"left_index\"),\n",
    "            how=\"left\",\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            suffixes=suffixes,\n",
    "        )\n",
    "        .drop(labels=[\"left_side\", \"right_side\"], axis=1)\n",
    "        .rename(columns={\"similarity\": \"match_probability\"})\n",
    "    )\n",
    "\n",
    "    return matches_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ngrams(string, n=3):\n",
    "    \"\"\"\n",
    "    Calculate n-grams for the input string.\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[,-./]|\\sBD\", r\"\", string)\n",
    "    ngrams = zip(*[string[i:] for i in range(n)])\n",
    "    return [\"\".join(ngram) for ngram in ngrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fast_cossim_top(A, B, ntop, lower_bound=0):\n",
    "    \"\"\"\n",
    "    Calculate the cosine similarity for the top matches.\n",
    "    \"\"\"\n",
    "    # force A and B as a CSR matrix.\n",
    "    # If they have already been CSR, there is no overhead\n",
    "    A = A.tocsr()\n",
    "    B = B.tocsr()\n",
    "    M, _ = A.shape\n",
    "    _, N = B.shape\n",
    "\n",
    "    idx_dtype = np.int32\n",
    "\n",
    "    nnz_max = M * ntop\n",
    "\n",
    "    indptr = np.zeros(M + 1, dtype=idx_dtype)\n",
    "    indices = np.zeros(nnz_max, dtype=idx_dtype)\n",
    "    data = np.zeros(nnz_max, dtype=A.dtype)\n",
    "\n",
    "    ct.sparse_dot_topn(\n",
    "        M,\n",
    "        N,\n",
    "        np.asarray(A.indptr, dtype=idx_dtype),\n",
    "        np.asarray(A.indices, dtype=idx_dtype),\n",
    "        A.data,\n",
    "        np.asarray(B.indptr, dtype=idx_dtype),\n",
    "        np.asarray(B.indices, dtype=idx_dtype),\n",
    "        B.data,\n",
    "        ntop,\n",
    "        lower_bound,\n",
    "        indptr,\n",
    "        indices,\n",
    "        data,\n",
    "    )\n",
    "\n",
    "    return csr_matrix((data, indices, indptr), shape=(M, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _format_matches(sparse_matrix, name_vector_unique, unique_index, left_size):\n",
    "    \"\"\"\n",
    "    Internal function to format the sparse matrix of matches \n",
    "    into a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    non_zeros = sparse_matrix.nonzero()\n",
    "\n",
    "    sparserows = non_zeros[0]\n",
    "    sparsecols = non_zeros[1]\n",
    "    nr_matches = sparsecols.size\n",
    "\n",
    "    out = []\n",
    "\n",
    "    for index in range(0, nr_matches):\n",
    "\n",
    "        # the left/right string match\n",
    "        left_side = name_vector_unique.iloc[sparserows[index]]\n",
    "        right_side = name_vector_unique.iloc[sparsecols[index]]\n",
    "\n",
    "        # the index in name vector\n",
    "        lidx = name_vector_unique.index[sparserows[index]]\n",
    "        ridx = name_vector_unique.index[sparsecols[index]]\n",
    "\n",
    "        # the original index\n",
    "        left_index = unique_index[lidx]\n",
    "        right_index = unique_index[ridx]\n",
    "\n",
    "        # similarity\n",
    "        similarity = sparse_matrix.data[index]\n",
    "\n",
    "        # FIXME\n",
    "        if lidx != ridx and lidx < left_size and ridx > left_size:\n",
    "            out.append([left_index, right_index, left_side, right_side, similarity])\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        out,\n",
    "        columns=[\"left_index\", \"right_index\", \"left_side\", \"right_side\", \"similarity\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "registry_id\n",
      "0       119 degrees architects\n",
      "1                      12bravo\n",
      "2         1st choice financial\n",
      "3                 212 harakawa\n",
      "4          215 media solutions\n",
      "                 ...          \n",
      "3114                     zoeza\n",
      "3115                     zones\n",
      "3116               zook motors\n",
      "3117                      zora\n",
      "3118              zweig ramick\n",
      "Name: company_name, Length: 3119, dtype: object\n",
      "right_index\n",
      "0         birmingham fire ins of pa t\n",
      "1                clayman edward p esq\n",
      "2                         brennan j f\n",
      "3                        tasty baking\n",
      "4                       magargee bros\n",
      "                     ...             \n",
      "203573                 1836 n 22nd st\n",
      "203574         el yiguity auto repair\n",
      "203575                   heta designs\n",
      "203576           wendell august forge\n",
      "203577         t c cleaning solutions\n",
      "Name: company_name, Length: 203541, dtype: object\n"
     ]
    }
   ],
   "source": [
    "tf_idf_merge(cleaned_registry, cleaned_license, on=\"company_name\", score_cutoff=85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
